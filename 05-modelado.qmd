# Modelado y Predicción del Comportamiento de Incendios

El cambio climático está intensificando las condiciones climáticas adversas, caracterizadas por temperaturas más altas y precipitaciones reducidas. Estas condiciones extremas, combinadas con la actividad humana en el territorio, incrementan significativamente el riesgo de ignición y propagación de incendios. Frente a esta amenaza, se vuelve esencial desarrollar herramientas capaces de predecir de manera precisa cómo y dónde se distribuirá el riesgo de incendio. En este contexto, los algoritmos de aprendizaje automático ofrecen un enfoque potente para identificar patrones en variables relacionadas con los incendios, lo que permite estimar la probabilidad de inicio de un incendio en áreas específicas. Este enfoque predictivo puede facilitar la planificación y gestión del riesgo, contribuyendo a la prevención y mitigación de incendios forestales.

Para el caso particular de los incendios forestales, *Random Forest* se ha usado ampliamente en combinación con datos históricos de ignición y variables relacionadas al fenómeno para identificar patrones y/o factores que promuevan la ignición y propagación de incendios.

En el siguiente ejemplo, trabajaremos para predecir la probabilidad de incendio de la Región de la Araucanía para el año 2016. Para realizar el ejercicio, tendrá que descargar el siguiente  [`.zip`](https://figshare.com/ndownloader/files/50336817). El archivo contiene:

-   Puntos de ignición

-   Puntos de no-ignición

-   Polígono con la zona de estudio

-   Imágen raster con variables predictoras con el siguiente orden:

    -   **B1**: Precipitación.

    -   **B2**: Distancia a caminos.

    -   **B3**: Distancia a zonas urbanas.

    -   **B4**: DEM.

    -   **B5**: Pendiente.





## Preparación de datos
Antes de comenzar, tendremos que cargar algunas librerías extras:

```{python}
import os
import pandas as pd
import geopandas as gpd
import numpy as np
import rasterio as rio
import rioxarray as rxr # <1>
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split # <2>
from sklearn.ensemble import RandomForestRegressor # <3>
from sklearn.metrics import roc_auc_score # <4>
```

1. `rioxarray` es una librería que combina capacidades de manejar datos multidimensionales con las capacidades de `rasterio`.
2.  `sklearn` es una de las librerías más ocupadas dentro de *Python* para el *Machine Learning*. En esta línea se está importando una función que facilita la extracción de puntos para muestras y las de validación.
3.  Del submódulo `ensemble` se ocupa *Random Forest* *Regressor* el cual, puede predecir valores continuos.
4.  Por útltimo, el submódulo `metrics` importa la función `AUC` que servirá para evaluar el rendimiento del modelo.

Una vez cargada las librerías, llamaremos a los datos. Estos se componen de puntos para ignición/no-ignición. Ambos servirán para el entrenamiento del modelo. Además del raster multibanda que alberga a las variables predictoras.

Lo primero es verificar que nuestros datos se encuentren en el mismo CRS:

```{python}
#| echo: false

os.chdir("recursos/rf")
```

```{python}
#| echo: true

coord_1 = gpd.read_file("puntos/si_ignicion_2016.shp") # Muestras igncion
coord_0 = gpd.read_file("puntos/no_ignicion_2016.shp") # Muestras no ignicion

# Imprimimos los atributos del raster
with rio.open('datos/datos_2016.tif') as src:
    crsRaster = src.crs
    print(f"El crs de los datos es {src.crs}\n"
          f"La cantidad de bandas (datos) es {src.count}")

datos_raster = rio.open('datos/datos_2016.tif') 
```

```{python}
if coord_1.crs == coord_0.crs == crsRaster:
    print("Todas las capas se encuentran en el mismo CRS")
else:
    print(f"coord1: {coord_1.crs}\n"
          f"coord2: {coord_2.crs}\n"
          f"raster:{datos_raster.crs}")
```

A través de una función que vamos a construir, obtendremos los datos de las variables en el raster usando las coordenadas de los puntos. Posteriormente, ambas listas se convierten a *DataFrame* y se les asigna una etiqueta. Por último, se unen ambos *DataFrames*:

```{python}
def ext_muestras(gdf_data, raster):
    # Crear lista de coordenadas
    coordenadas = []

    # Extrae un punto con sus coordenadas
    for punto in gdf_data.geometry:
        coordenada = (punto.x, punto.y)
        coordenadas.append(coordenada)
    
    # Crear lista de muestras
    muestras = []

    # Por cada muestra, extrae el valor del raster
    for muestra in raster.sample(coordenadas):
        muestras.append(muestra)
        
    return muestras

# Aplicamos la funcion en ambos puntos (ignición y no ignición) y trasnforman a df
muestras_1 = ext_muestras(coord_1, datos_raster)
df_1 = pd.DataFrame(muestras_1)
df_1["etiqueta"] = 1

muestras_0 = ext_muestras(coord_0, datos_raster)
df_0 = pd.DataFrame(muestras_0)
df_0["etiqueta"] = 0

# Concatenar primero los DataFrames
df = pd.concat([df_1, df_0])

df.head()
```

Para ingresar los datos correctamente al algoritmo de *Random Forest*, debemos separar los datos en dos arrays. Uno conteniendo únicamente los valores de los datos y otro conteniendo las etiquetas para cada observación.

```{python}
X = df.drop('etiqueta', axis=1).to_numpy()
y = df['etiqueta'].to_numpy()

print(f"Array con valores \n"
      f"{X}")

print(f"Array con etiquetas\n"
      f" {y}")
```

## Entrenamiento

```{python}
#| output: false
# Particion de datos
trainX, testX, trainy, testy = train_test_split(X, # <1>
                                                y, # <1>
                                                test_size = 0.3, # <1> 
                                                shuffle = True) # <1>
# Activar el modelo RandomForestRegressor
modelo_RF = RandomForestRegressor()

# Entrena el modelo con los datos de entrenamiento
modelo_RF.fit(trainX, trainy) # <2>
```

1. La función `train_test_split` divide los datos para porciones de entrenamiento y de test. Como input necesita el array con los valores de los datos (`X`), un array con las etiquetas (`y`), el tamaño de datos para la prueba (`test_size`) y establecer si mezclar los datos (`shuffle`). Como outputs se obtienen los conjuntos de entrenamiento y de test tanto de `X` como de `y`.

2. `modelo_RF.fit` entrena el modelo utilizando los datos de entrenamiento. Durante este, el modelo aprende relaciones entre las características y las etiquetas en los datos de entrenamiento.

## Predicción y validación

Para predecir deberemos ocupar la función `.predict`:

```{python}
# Realizar predicciones con los datos de X
predicciones = modelo_RF.predict(X = testX)

# Obtiene AUC para la estimación del desempeño.
metrica = roc_auc_score(testy, predicciones)

print(f"AUC: {metrica}")
```

## Prediciendo con el modelo

```{python}

data = rxr.open_rasterio('datos/datos_2016.tif') # <1>

pixeles = data.values.transpose(1,2,0) # <2>

pixeles_t = pixeles.reshape(-1, 5) # <3>

pred_2016 = modelo_RF.predict(pixeles_t) # <4>

mapa_pred = pred_2016.reshape(pixeles.shape[0], # <5>
                              pixeles.shape[1]) # <5>

resultado = data[0].copy() # <6>
resultado.values = mapa_pred # <6>
```

1.  Se carga el mismo raster con los datos, excepto que ahora se hace con `rioxarray`.
2.  Transpone los datos del raster para que las bandas estén en el último eje. En este caso pasa de una estructura (bandas, filas, columnas) a (filas, columnas, bandas).
3.  Reorganiza los datos en un array de 2 dimensiones. Aquí, el `-1` permite que NumPy calcule automáticamente el tamaño de la primera dimensión, mientras que el `5` es el número de bandas. 
4.  Ocupa el modelo entrenado para hacer las predicciones sobre los datos reorganizados.
5.  Se reorganizan de nuevo las predicciones para obtener la forma original del raster.
6.  Se crea una copia del raster original y asigna las predicciones a los valores del raster.

Para observar el resultado del modelo podemos usar *Matplotlib*.

:::{.column-body-outset}
```{python}
#| fig-align: center
#| warning: false
fig, ax = plt.subplots(figsize=(10, 10))

resultado.plot(
    ax = ax,
    cmap = 'viridis',
    add_colorbar = True,
    cbar_kwargs = {'label': 'Probabilidad de ignición'})

coord_1.plot(
    ax = ax,
    color = 'red',
    markersize= 15,
    label = 'Ignición')

ax.set_title('Probabilidad de ignición año 2016')
ax.set_ylabel("")
ax.set_xlabel("")


ax.legend()
plt.show()
```
:::

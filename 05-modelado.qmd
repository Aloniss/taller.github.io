# Modelado y Predicción del Comportamiento de Incendios

En el contexto del Cambio Climático, los incendios forestales han aumentado en frecuencia y magnitud por todo el globo. ...
Es en esta línea que intentan poder crear modelos matemáticos capaces de modelar el comportamiendo del fuego a través de condiciones meteorológicas, físicas, asociadas a la vegetación y asi poder predecir las instancias en que se provocan las igniciones y la expansión del fuego.

Una de las principales técnicas ocupadas ha sido el *Random Forest*, un algoritmo de aprendizaje automático supervisado. 

El *Random Forest* se constituye a través de varios árboles de condición, donde cada árbol se entrena con un sample o muestra aleatoria y se realiza una predicción independiente. Posterior a eso, se juntan todas las predicciones de los árboles para obtener una predicción final. El árbol más votado sale como predicción.

Para el caos de los incendios forestales, el Random Fores se puede emplear para realizar análisis de datos históricos y apartir de estos, identificar posibles patrones y/o factores que promuevan la ignición y propagación de incendios y así, poder predecir eventos de esta índole hacia el futuro.

En el siguiente ejemplo, trabajaremos para predecir la probabilidad de incendio de **algo** para el año 2016. Para realizar el ejercicio, tendrá que descargar el siguiente [`.zip`](https://figshare.com/ndownloader/files/50336817). Este contiene ...

## Preparación de datos
Antes de comenzar, tendremos que cargar algunas librerías extras:

```{python}
import os
import pandas as pd
import geopandas as gpd
import numpy as np
import rasterio as rio
import rioxarray as rxr # <1>
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split # <2>
from sklearn.ensemble import RandomForestRegressor # <3>
from sklearn.metrics import roc_auc_score # <4>
```

1. `rioxarray` es una librería que combina capacidades de manejar datos multidimensionales con las capacidades de `rasterio`.
2.  `sklearn` es una de las librerías más ocupadas dentro de *Python* para el *Machine Learning*. En esta línea se está importando una función que facilita la extracción de puntos para muestras y las de validación.
3.  Del submódulo `ensemble` se ocupa *Random Forest* *Regressor* el cual, predece valores continuos.
4.  Por útltimo, el submódulo `metrics` importa la la función `AUC` que servirpa para evalaur el rendimiento de la clasificación.

Una vez cargada las librerías, cargaremos los datos. Estos se componen en puntos donde se sabe que hubo alguna ignición y de puntos donde no ha habido/hubo* ignición. Ambos nos servirán para el entrenamiento del modelo. Además, tendremos un raster multibanda, con la consideración de que las bandas no representan un atributo del espectro electromagnético, sino que una variable.

```{python}
#| echo: false

os.chdir("recursos/rf")
```

```{python}
#| echo: false
#| 
coord_1 = gpd.read_file("puntos/si_ignicion_2016.shp") # muestras igncion
coord_0 = gpd.read_file("puntos/no_ignicion_2016.shp") # Meustras no ignicion

# Imprimimos los atributos del raster
with rio.open('datos/datos_2016.tif') as src:
    crsRaster = src.crs
    print(f"El crs de los datos es {src.crs}\n"
          f"La cantidad de bandas (datos) es {src.count}")

datos_raster = rio.open('datos/datos_2016.tif') 
```

Debemos verificar que nuestros datos se encuentren en el mismo CRS:
```{python}
if coord_1.crs == coord_0.crs == crsRaster:
    print("Todas las capas se encuentran en el mismo CRS")
else:
    print(f"coord1: {coord_1.crs}\n"
          f"coord2: {coord_2.crs}\n"
          f"raster:{datos_raster.crs}")
```

Ahora, a través de una función, obtendremos datos de las variables en el raster con las coordenadas de los puntos. Despues, ambas listas se convierten a *DataFrame* y se les asigna una etiqueta. Por último, se unen ambos `DataFrames`:

```{python}
def ext_muestras(gdf_data, raster):
    # Crear lista de coordenadas
    coordenadas = []

    # Extrae un punto con sus coordenadas
    for punto in gdf_data.geometry:
        coordenada = (punto.x, punto.y)
        coordenadas.append(coordenada)
    
    # Crear lista de muestras
    muestras = []

    # Por cada muestra, extrae el valor del raster
    for muestra in raster.sample(coordenadas):
        muestras.append(muestra)
        
    return muestras

# Aplicamos la funcion en ambos puntos (ignición y no ignición) y trasnforman a df
muestras_1 = ext_muestras(coord_1, datos_raster)
df_1 = pd.DataFrame(muestras_1)
df_1["etiqueta"] = 1

muestras_0 = ext_muestras(coord_0, datos_raster)
df_0 = pd.DataFrame(muestras_0)
df_0["etiqueta"] = 0

# Concatenar primero los DataFrames
df = pd.concat([df_1, df_0])

df.head()
```

Para poder ingresar los datos correctamente al modelo debemos inputar dos arrays. Uno conteniendo únicamente los valores de los datos y otro conteniendo las etiquetas de estas:
```{python}
X = df.drop('etiqueta', axis=1).to_numpy()
y = df['etiqueta'].to_numpy()

print(f"Array con valores \n"
      f"{X}")

print(f"Array con etiquetas\n"
      f" {y}")
```

## Entrenamiento

```{python}
#| output: false
# Particion de datos
trainX, testX, trainy, testy = train_test_split(X, # <1>
                                                y, # <1>
                                                test_size = 0.3, # <1> 
                                                shuffle = True) # <1>
# Activar el modelo RandomForestRegressor
modelo_RF = RandomForestRegressor()

# Entrena el modelo con los datos de entrenamiento
modelo_RF.fit(trainX, trainy) # <2>
```

1. La función `train_test_split` divide los datos para porciones de entrenamiento y de test. Como input necesita el array con los valores de los datos (`X`), un array con las etiquetas (`y`), el tamaño de datos para la prueba (`test_size`) y establecer si mezclar los datos (`shuffle`). Como outputs se obtienen los conjuntos de entrenamiento y de test tanto de `X` como de `y`.

2. `modelo_RF.fit` entrena el modelo utilizando los datos de entrenamiento. Durante este, el modelo aprende relaciones entre las características y las etiquetas en los datos de entrenamiento.

## Predicción y validación

Para predecir deberemos ocupar la función `.predict`:

```{python}
# Realizar predicciones con los datos de X
predicciones = modelo_RF.predict(X = testX)

# Obtiene AUC para validar
metrica = roc_auc_score(testy, predicciones)

print(f"AUC: {metrica}")
```

## Probando el modelo

```{python}

data = rxr.open_rasterio('datos/datos_2016.tif') # <1>

pixeles = data.values.transpose(1,2,0) # <2>

pixeles_t = pixeles.reshape(-1, 5) # <3>

pred_2016 = modelo_RF.predict(pixeles_t) # <4>

mapa_pred = pred_2016.reshape(pixeles.shape[0], # <5>
                              pixeles.shape[1]) # <5>

resultado = data[0].copy() # <6>
resultado.values = mapa_pred # <6>
```

1.  Se carga el mismo raster, con la salvedad de abrirlo con `rioxarray`.
2.  Transpone los datos del raster para que las bandas estén en el último eje. En este caso pasa de (bandas, filas, columnas) a (filas, columnas, filas).
3.  Reorganiza los datos en un array de 2 dimensiones. Aquí, el `-1` permite que `NumPy` calcule automáticamente el tamaño de la primera dimensión, mientras que el `5` es el número de bandas. 
4.  Ocupa el modelo entrenado para hacer las predicciones sobre los datos reorganizados.
5.  Se reorganiza de nuevo las predicciones para obtener la forma original del raster.
6.  Se crea una copia del raster original y asigna las predicciones a los valores del raster.

Para observar las predicciones, podemos graficarlas gracias a *Matplotlib*

```{python}
#| fig-align: center
fig, ax = plt.subplots()

resultado.plot(
    ax = ax,
    cmap = 'viridis',
    add_colorbar = True,
    cbar_kwargs = {'label': 'Probabilidad de ignición'})

coord_1.plot(
    ax = ax,
    color = 'red',
    markersize= 30,
    label = 'Ignición')

ax.set_title('Mapa de predicción de ignición 2016')
ax.legend()
plt.show()
```

